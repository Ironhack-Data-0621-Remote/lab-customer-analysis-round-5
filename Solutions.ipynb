{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "934ae21a",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Round 5\n",
    "\n",
    "For this lab, we still keep using the `marketing_customer_analysis.csv` file that you can find in the `files_for_lab` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e4dfe-5c6a-4e88-9317-c64f42d6c1a3",
   "metadata": {},
   "source": [
    "### 1. Get the data\n",
    "\n",
    "We are using the `marketing_customer_analysis.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b94cb1-93d4-4589-895f-0545c0bc6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214b5a-1c51-4c0d-94a2-ff56d26bc8ff",
   "metadata": {},
   "source": [
    "### 2. Dealing with the data\n",
    "\n",
    "Already done in the round 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0d30c-a05d-4fe7-bff6-89df549a35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d67e66-32fb-49ed-a091-786e12e60119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dfheaders(df):\n",
    "    df.rename(columns={'Customer':'id', 'EmploymentStatus':'employment_status'}, inplace=True)\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "# using the 2 operations together only works when removing the 'df=' infront of the first satemment. Why?\n",
    "# the first operation doesnt work at all in a function without the inplace parameter. Outside of a function it does work. Why?\n",
    "\n",
    "clean_dfheaders(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b5d0e",
   "metadata": {},
   "source": [
    "### 3. Explore the data\n",
    "\n",
    "Some datasets have values that are missing, invalid, or otherwise difficult for an algorithm to process. If data is missing, the algorithm canâ€™t use it. If data is invalid, the algorithm produces less accurate or even misleading outcomes. Some datasets are relatively clean but need to be shaped (e.g., aggregated or pivoted) and many datasets are just lacking useful business context (e.g., poorly defined ID values), hence the need for feature enrichment. Good data preparation produces clean and well-curated data which leads to more practical, accurate model outcomes.\n",
    "\n",
    "\n",
    "   **3.1.- Determine the problems**\n",
    "    \n",
    "   **3.2.- Data cleaning** Cleaning the data is very important as the model learning from that data only, so if we feed inconsistent, appropriate data to model it will return garbage only, so it is required to make sure that the data does not contains any unseen problem.\n",
    "     \n",
    "       - Feature and Target Variables\n",
    "       - Data Types\n",
    "       - Missing data, check null values\n",
    "       - Outliers\n",
    "       - Duplicate data\n",
    "        \n",
    "   **3.3.- Feature selection** (Which variables are important to answer our questions?)\n",
    "    \n",
    "   **3.4.- Data transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777977-f35a-45d8-aa90-e59019655159",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['effective_to_date'] = pd.to_datetime(data['effective_to_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860574af-b5af-4d46-beb6-a3c5975ae859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Nan values to take care of anymore, so checking if there are values  <= 0 in the numerical columns and replaceing them where it makes sense\n",
    "number_col = list(data.select_dtypes(include=[np.number]).columns.values)\n",
    "\n",
    "for col in number_col:\n",
    "    neg_val = len(data[data[col] < 0])\n",
    "    zero_val = len(data[data[col] == 0])\n",
    "     \n",
    "    if neg_val > 0:\n",
    "        print('Negative values in', col, ':', neg_val)\n",
    "    elif zero_val > 0:\n",
    "        print('Zeros in', col, ':', zero_val)\n",
    "    else:\n",
    "        print('Column', col, 'is ok.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36bf7-9e8d-429c-8806-2274f7ae2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing 0 only makes sense in 'income'\n",
    "data1 = data.copy()\n",
    "data1['income'] = np.where(data['income'] == 0, data['income'].median(), data['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3583925-8a28-439f-8a39-7c82fd4f3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.duplicated(subset=['id']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f02eb9-7e3c-421e-8e27-7d2c54923439",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(data1.select_dtypes(include=[np.number]).columns.values)\n",
    "\n",
    "for col in num_col:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=data1[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ea801-7007-4542-b5a0-47b8e112b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers where it makes sense\n",
    "outl_col = ['customer_lifetime_value', 'monthly_premium_auto', 'number_of_policies', 'total_claim_amount']\n",
    "\n",
    "for col in outl_col:\n",
    "    iqr = np.percentile(data1[col],75) - np.percentile(data1[col],25)\n",
    "    upper_limit = np.percentile(data1[col],75) + 1.5*iqr\n",
    "    lower_limit = np.percentile(data1[col],25) - 1.5*iqr\n",
    "    data1.loc[data1[col] > upper_limit, col] = upper_limit\n",
    "    data1.loc[data1[col] < lower_limit, col] = lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d142871-84f9-47b1-8b0c-2b3296dc2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08de5d9-a288-464f-ac5a-0a147983935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_corr = data1.corr()\n",
    "data1_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fceee2-f456-491f-9293-8a91698edb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_col:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.distplot(data1[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e226d01-69a9-40c1-8289-3cbbada8aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no column is really promisssing, evaluated by looking at correlations with monthly_premium_auto being the best among them\n",
    "#transforming except for 'number_of_open_complaints' and 'number_of_policies' because they sem to trend towards certain values which I dont want to lose by transforming and normalizing\n",
    "\n",
    "data_t = data1.copy()\n",
    "trans_col = ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'total_claim_amount']\n",
    "#data_t['months_since_policy_inception'] = np.where(data_t['months_since_policy_inception']<=0, 0.1, data_t['months_since_policy_inception']) doesnt work. Why?\n",
    "\n",
    "for col in trans_col:\n",
    "    transformed_col, _ci = stats.boxcox(data1[col])\n",
    "    data_t[col] = transformed_col\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.distplot(data_t[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb74a3a-eee0-40a0-9c34-61be038eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t_corr = data_t.corr()\n",
    "data_t_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683248d-f3a7-4672-ab1f-b7abe274c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since correlation for monthly_premium_auto decreased after transforming the column, I'm using the original data instead\n",
    "data_t['monthly_premium_auto'] = data1['monthly_premium_auto']\n",
    "data_t['total_claim_amount'] = data1['total_claim_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44f9c3",
   "metadata": {},
   "source": [
    "### 4. Processing Data\n",
    "\n",
    "(_Further processing..._)\n",
    "\n",
    "- X-y split.\n",
    "- Normalize (numerical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1ba69-3192-43aa-8530-d2b32d21fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model before normalizing and standardizing\n",
    "t_num = list(data_t.select_dtypes(include=[np.number]).columns.values)\n",
    "t_object = list(data_t.select_dtypes(include=[np.object]).columns.values)\n",
    "\n",
    "t_drop = t_object + [t_num[7]] + ['effective_to_date']\n",
    "t_x = data_t.drop(t_drop, axis=1)\n",
    "t_y = data_t['total_claim_amount']\n",
    "\n",
    "lm = LinearRegression()\n",
    "model2 = lm.fit(t_x,t_y)\n",
    "t_predictions = lm.predict(t_x)\n",
    "t_rmse = mean_squared_error(t_y, t_predictions, squared=False)\n",
    "\n",
    "print(\"R2_score:\", round(lm.score(t_x,t_y),2))\n",
    "print(\"RMSE:\", t_rmse)\n",
    "\n",
    "t_x = sm.add_constant(t_x)\n",
    "model = sm.OLS(t_y,t_x).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641a958-0d87-4b40-8e0c-bd6251573208",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_t['total_claim_amount']\n",
    "x = data_t.drop(['total_claim_amount'], axis=1)\n",
    "data_sn = x.select_dtypes(include=np.number)\n",
    "\n",
    "transformer = Normalizer()\n",
    "transformer.fit(data_sn)\n",
    "x_normalized = transformer.transform(data_sn)\n",
    "data_sn = pd.DataFrame(x_normalized)\n",
    "\n",
    "transformer = StandardScaler()\n",
    "transformer.fit(data_sn)\n",
    "x_standardized = transformer.transform(data_sn)\n",
    "data_sn = pd.DataFrame(x_standardized)\n",
    "\n",
    "sn_col = ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'months_since_last_claim', 'months_since_policy_inception', 'number_of_open_complaints', 'number_of_policies']\n",
    "\n",
    "for idx, col in enumerate(sn_col):\n",
    "    data_sn.rename(columns={idx:col}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2773c-c5b3-43ef-bbfe-c0fcde546a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sn_col:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.distplot(data_sn[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755dc0f-6708-4896-acfc-f0d977c09931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model after normalizing and standardizing\n",
    "sn_x = data_sn\n",
    "sn_y = data_t['total_claim_amount']\n",
    "\n",
    "lm_sn = LinearRegression()\n",
    "model_sn2 = lm_sn.fit(sn_x,sn_y)\n",
    "sn_predictions = lm_sn.predict(sn_x)\n",
    "sn_rmse = mean_squared_error(sn_y, sn_predictions, squared=False)\n",
    "\n",
    "print(\"R2_score:\", round(lm_sn.score(sn_x,sn_y),2))\n",
    "print(\"RMSE:\", sn_rmse)\n",
    "\n",
    "sn_x = sm.add_constant(sn_x)\n",
    "model_sn = sm.OLS(sn_y,sn_x).fit()\n",
    "\n",
    "print(model_sn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba62f0-7134-4439-95f0-be6bb4370eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3Brew",
   "language": "python",
   "name": "python3brew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
